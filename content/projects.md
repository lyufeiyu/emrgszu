This project is grounded in the core research strengths of our group and aims to advance the frontiers of intelligent computation. Its scope encompasses several interconnected directions:

* **Evolutionary Intelligence**<br>
  We investigate evolutionary principles as a foundation for learning, adaptation, and problem-solving in complex environments. By leveraging population-based search and self-adaptive mechanisms, the project seeks to design robust algorithms capable of discovering novel and efficient solutions.

* **Multi-objective and Many-task Optimization**<br>
  The project emphasizes optimization under multiple, often conflicting objectives, as well as the simultaneous handling of diverse tasks. Our goal is to develop scalable frameworks that balance trade-offs and enable knowledge transfer across tasks, ultimately improving efficiency in high-dimensional and dynamic settings.

* **Distributed and Reinforcement Learning**<br>
  We study intelligent decision-making in decentralized and interactive systems. Through the integration of distributed learning and reinforcement learning, the project explores strategies for scalable coordination, adaptive control, and autonomous behavior under uncertainty.

* **Multimodal Signal Processing under Resource Constraints**<br>
  Recognizing the complexity of real-world data, we address multimodal learning and signal processing where computational and memory resources are limited. The project aims to design lightweight yet powerful models that maintain effectiveness in constrained scenarios.

By integrating these directions, the project aspires to construct **scalable, adaptive, and resource-efficient learning paradigms**. It seeks not only to enrich the theoretical foundations of machine intelligence but also to provide general frameworks that inform the next generation of AI systems.
